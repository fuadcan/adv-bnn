{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro\n",
    "import tqdm\n",
    "import os, pickle\n",
    "import common\n",
    "\n",
    "# Reproducibility\n",
    "common.set_seed(156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(torch.nn.Module):\n",
    "    def __init__(self, ni, nh, no):\n",
    "        super(NN, self).__init__()\n",
    "        self.A = torch.nn.Linear(ni, nh)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.B = torch.nn.Linear(nh, no)\n",
    "    def forward(self, x):\n",
    "        # Two layer neural network\n",
    "        x = self.B(self.relu(self.A(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataset\n",
    "train_dataset = torchvision.datasets.MNIST('.', train=True, download=True,\n",
    "                       transform=torchvision.transforms.ToTensor())\n",
    "# Train data loader\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "# Point estimate NN\n",
    "net = NN(28*28, 1024, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x, y):\n",
    "    # Put priors on weights and biases \n",
    "    priors = {\n",
    "        \"A.weight\": pyro.distributions.Normal(\n",
    "            loc=torch.zeros_like(net.A.weight), \n",
    "            scale=torch.ones_like(net.A.weight),\n",
    "        ).independent(2),\n",
    "        \"A.bias\": pyro.distributions.Normal(\n",
    "            loc=torch.zeros_like(net.A.bias), \n",
    "            scale=torch.ones_like(net.A.bias),\n",
    "        ).independent(1),\n",
    "        \"B.weight\": pyro.distributions.Normal(\n",
    "            loc=torch.zeros_like(net.B.weight), \n",
    "            scale=torch.ones_like(net.B.weight),\n",
    "        ).independent(2),\n",
    "        \"B.bias\": pyro.distributions.Normal(\n",
    "            loc=torch.zeros_like(net.B.bias), \n",
    "            scale=torch.ones_like(net.B.bias),\n",
    "        ).independent(1),\n",
    "    }\n",
    "    # Create a NN module using the priors\n",
    "    lmodule = pyro.random_module(\"module\", net, priors)\n",
    "    regressor = lmodule()\n",
    "    # Do a forward pass on the NN module, i.e. yhat=f(x) and condition on yhat=y\n",
    "    lhat = torch.nn.LogSoftmax(dim=1)(regressor(x))\n",
    "    pyro.sample(\"obs\", pyro.distributions.Categorical(logits=lhat).independent(1), obs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "softplus = torch.nn.Softplus()\n",
    "def guide(x, y):\n",
    "    # Create parameters for variational distribution priors\n",
    "    Aw_mu = pyro.param(\"Aw_mu\", torch.randn_like(net.A.weight))\n",
    "    Aw_sigma = softplus(pyro.param(\"Aw_sigma\", torch.randn_like(net.A.weight)))\n",
    "    Ab_mu = pyro.param(\"Ab_mu\", torch.randn_like(net.A.bias))\n",
    "    Ab_sigma = softplus(pyro.param(\"Ab_sigma\", torch.randn_like(net.A.bias)))\n",
    "    Bw_mu = pyro.param(\"Bw_mu\", torch.randn_like(net.B.weight))\n",
    "    Bw_sigma = softplus(pyro.param(\"Bw_sigma\", torch.randn_like(net.B.weight)))\n",
    "    Bb_mu = pyro.param(\"Bb_mu\", torch.randn_like(net.B.bias))\n",
    "    Bb_sigma = softplus(pyro.param(\"Bb_sigma\", torch.randn_like(net.B.bias)))\n",
    "    # Create random variables similarly to model\n",
    "    priors = {\n",
    "        \"A.weight\": pyro.distributions.Normal(loc=Aw_mu, scale=Aw_sigma).independent(2),\n",
    "        \"A.bias\"  : pyro.distributions.Normal(loc=Ab_mu, scale=Ab_sigma).independent(1),\n",
    "        \"B.weight\": pyro.distributions.Normal(loc=Bw_mu, scale=Bw_sigma).independent(2),\n",
    "        \"B.bias\"  : pyro.distributions.Normal(loc=Bb_mu, scale=Bb_sigma).independent(1),\n",
    "    }\n",
    "    # Return NN module from these random variables\n",
    "    lmodule = pyro.random_module(\"module\", net, priors)\n",
    "    return lmodule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do stochastic variational inference to find q(w) closest to p(w|D)\n",
    "svi = pyro.infer.SVI(\n",
    "    model, guide, pyro.optim.Adam({'lr': 0.01}), pyro.infer.Trace_ELBO(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_models(epochs = 10, K = 100, modelname = \"model.pt\"):\n",
    "    if os.path.exists(modelname):\n",
    "        print(\"File exists\")\n",
    "        return\n",
    "    # Train with SVI\n",
    "    for epoch in range(epochs):\n",
    "        loss = 0.\n",
    "        for data in train_loader:\n",
    "            images, labels = data\n",
    "            images = images.view(-1, 28*28)\n",
    "            loss += svi.step(images, labels)\n",
    "        loss /= len(train_loader.dataset)\n",
    "        print(\"Epoch %g: Loss = %g\" % (epoch, loss))\n",
    "    # Sample k models from the posterior\n",
    "    sampled_models = [guide(None, None) for i in range(K)]\n",
    "    # Save the models\n",
    "    nn_dicts = []\n",
    "    for i in range(len(sampled_models)):\n",
    "        nn_dicts += [sampled_models[i].state_dict()]\n",
    "    torch.save(nn_dicts, modelname)\n",
    "    print(\"Saved %d models\" % K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(K = 100, model_dir=\"models/model.pt\"):\n",
    "    # Load the models\n",
    "    sampled_models = [NN(28*28, 1024, 10) for i in range(K)]\n",
    "    for net, state_dict in zip(sampled_models, torch.load(model_dir)):\n",
    "        net.load_state_dict(state_dict)\n",
    "    print(\"Loaded %d sample models\" % K)\n",
    "    return sampled_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_and_save_models(epochs = 10, K = 100, modelname = \"model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [d for d in os.listdir(\"mnist_adv/\") if \"test_images_med\" in d]\n",
    "\n",
    "images  = []\n",
    "targets = []\n",
    "for d in dirs:\n",
    "    with open(\"mnist_adv/\"+d, 'rb') as handle:\n",
    "        temp = pickle.load(handle)\n",
    "        images.append(temp[\"images\"])\n",
    "        targets.append(temp[\"labels\"])\n",
    "        \n",
    "images  = torch.vstack(images)\n",
    "targets = torch.hstack(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset\n",
    "test_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "# Test data loader with batch_size 128\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))\n",
    "\n",
    "# AdvTest dataset\n",
    "adv_test_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=torchvision.transforms.ToTensor())\n",
    "adv_test_dataset.data    = None\n",
    "adv_test_dataset.targets = None\n",
    "\n",
    "adv_test_dataset.data    = images\n",
    "adv_test_dataset.targets = targets\n",
    "\n",
    "# Test data loader with batch_size 1\n",
    "adv_test_loader = torch.utils.data.DataLoader(adv_test_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(torch.nn.Module):\n",
    "    def __init__(self, ni, nh, no):\n",
    "        super(NN, self).__init__()\n",
    "        self.A = torch.nn.Linear(ni, nh)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.B = torch.nn.Linear(nh, no)\n",
    "        self.logsoftmax = torch.nn.LogSoftmax(dim=-1)\n",
    "    def forward(self, x):\n",
    "        # Two layer neural network\n",
    "        x = self.B(self.relu(self.A(x)))\n",
    "        x = self.logsoftmax(x)\n",
    "        return x\n",
    "class DeepNN(torch.nn.Module):\n",
    "    def __init__(self, ni, nh, no):\n",
    "        super(DeepNN, self).__init__()\n",
    "        self.fwd = torch.nn.Sequential(\n",
    "            torch.nn.Linear(ni, nh), torch.nn.ReLU(),\n",
    "            torch.nn.Linear(nh, nh), torch.nn.ReLU(),\n",
    "            torch.nn.Linear(nh, no),\n",
    "            torch.nn.LogSoftmax(dim=-1))\n",
    "    def forward(self, x):\n",
    "        # Two layer neural network\n",
    "        x = self.fwd(x)\n",
    "        return x\n",
    "class DeepNNwBN(torch.nn.Module):\n",
    "    def __init__(self, ni, nh, no):\n",
    "        super(DeepNNwBN, self).__init__()\n",
    "        self.fwd = torch.nn.Sequential(\n",
    "            torch.nn.BatchNorm1d(ni),\n",
    "            torch.nn.Linear(ni, nh), torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm1d(nh),\n",
    "            torch.nn.Linear(nh, nh), torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm1d(nh),\n",
    "            torch.nn.Linear(nh, no),\n",
    "            torch.nn.LogSoftmax(dim=-1))\n",
    "    def forward(self, x):\n",
    "        # Two layer neural network\n",
    "        x = self.fwd(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(model, loader):\n",
    "    total_correct = 0\n",
    "    for data in loader:\n",
    "        images, labels = data\n",
    "        images = images.view(-1, 28*28)\n",
    "        y    = model(images)\n",
    "        pred = torch.argmax(y, dim=1)\n",
    "        total_correct += torch.sum(pred==labels).item()\n",
    "    return total_correct / len(loader.dataset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "FFNN          = torch.load(\"models/FFNN_ep10.pt\")\n",
    "AdvFFNN       = torch.load(\"models/AdvFFNN_eps0.05_ep10.pt\")\n",
    "AdvFFNN_eps18 = torch.load(\"models/AdvFFNN_eps0.18_ep10.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "AdvDeepFFNN_eps18    = torch.load(\"models/AdvDeepFFNN_eps0.18_loss0.00108.pt\")\n",
    "AdvDeepFFNNwBN_eps18 = torch.load(\"models/AdvDeepFFNNwBN_eps0.18_loss0.00065.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFNN vs AdvFFNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9741"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(FFNN, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9742"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(AdvFFNN, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9691"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(AdvFFNN_eps18, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9788"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(AdvDeepFFNNwBN_eps18, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adversarial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8545735677083334"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(FFNN, adv_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8892415364583334"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(AdvFFNN, adv_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9817708333333334"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(AdvFFNN_eps18, adv_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9935709635416666"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(AdvDeepFFNNwBN_eps18, adv_test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdvBNN vs BNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50 sample models\n",
      "Loaded 50 sample models\n",
      "Loaded 50 sample models\n"
     ]
    }
   ],
   "source": [
    "sampled_models         = load_models(K = 50)\n",
    "sampled_adv_models     = load_models(K = 50, model_dir=\"models/AdvBNN_85.0808.pt\")\n",
    "sampled_adv_models_e18 = load_models(K = 50, model_dir=\"models/models_v1/AdvBNN_87.3814625.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.8216\n",
      "mean:  0.772208 , sd:  0.0256\n",
      "min:  0.7098\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, test_loader) for model in sampled_adv_models]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN(eps=18) vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.813\n",
      "mean:  0.7480020000000002 , sd:  0.033\n",
      "min:  0.6639\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, test_loader) for model in sampled_adv_models_e18]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BNN vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.8345\n",
      "mean:  0.7660100000000001 , sd:  0.0372\n",
      "min:  0.6509\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, test_loader) for model in sampled_models]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN vs Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.4938151041666667\n",
      "mean:  0.41070475260416667 , sd:  0.0476\n",
      "min:  0.2970377604166667\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_loader) for model in  sampled_adv_models]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN(eps=0.18) vs Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.5582682291666666\n",
      "mean:  0.4850781249999999 , sd:  0.0425\n",
      "min:  0.384521484375\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_loader) for model in  sampled_adv_models_e18]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BNN vs. Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.42919921875\n",
      "mean:  0.28287109375 , sd:  0.0808\n",
      "min:  0.1669921875\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_loader) for model in  sampled_models]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Test (eps=0.18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [d for d in os.listdir(\"mnist_adv_eps0.05/\") if \"test_images_med\" in d]\n",
    "\n",
    "images  = []\n",
    "targets = []\n",
    "for d in dirs:\n",
    "    with open(\"mnist_adv_eps0.05/\"+d, 'rb') as handle:\n",
    "        temp = pickle.load(handle)\n",
    "        images.append(temp[\"images\"])\n",
    "        targets.append(temp[\"labels\"])\n",
    "        \n",
    "images  = torch.vstack(images)\n",
    "targets = torch.hstack(targets)\n",
    "# Test dataset\n",
    "test_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "# Test data loader with batch_size 128\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))\n",
    "\n",
    "# AdvTest dataset\n",
    "adv_test_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=torchvision.transforms.ToTensor())\n",
    "adv_test_dataset.data    = None\n",
    "adv_test_dataset.targets = None\n",
    "\n",
    "adv_test_dataset.data    = images\n",
    "adv_test_dataset.targets = targets\n",
    "\n",
    "# Test data loader with batch_size 1\n",
    "adv_test_loader = torch.utils.data.DataLoader(adv_test_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFNN vs AdvFFNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9741"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(FFNN, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9742"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(AdvFFNN, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9681"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(AdvFFNN_eps18, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adversarial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9907272196261683"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(FFNN, adv_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9914573598130841"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(AdvFFNN, adv_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9802862149532711"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(AdvFFNN_eps18, adv_test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdvBNN vs BNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50 sample models\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/AdvBNN_85.0808.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-686984d1dbe9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msampled_models\u001b[0m         \u001b[0;34m=\u001b[0m \u001b[0mload_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msampled_adv_models\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mload_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"models/AdvBNN_85.0808.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msampled_adv_models_e18\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"models/models_v1/AdvBNN_87.3814625.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-896a956bf324>\u001b[0m in \u001b[0;36mload_models\u001b[0;34m(K, model_dir)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Load the models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msampled_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loaded %d sample models\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/AdvBNN_85.0808.pt'"
     ]
    }
   ],
   "source": [
    "sampled_models         = load_models(K = 50)\n",
    "sampled_adv_models     = load_models(K = 50, model_dir=\"models/AdvBNN_85.0808.pt\")\n",
    "sampled_adv_models_e18 = load_models(K = 50, model_dir=\"models/models_v1/AdvBNN_87.3814625.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.8216\n",
      "mean:  0.772208 , sd:  0.0256\n",
      "min:  0.7098\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, test_loader) for model in sampled_adv_models]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN(eps=18) vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.813\n",
      "mean:  0.7480020000000002 , sd:  0.033\n",
      "min:  0.6639\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, test_loader) for model in sampled_adv_models_e18]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BNN vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.8345\n",
      "mean:  0.7660100000000001 , sd:  0.0372\n",
      "min:  0.6509\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, test_loader) for model in sampled_models]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN vs Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.7754088785046729\n",
      "mean:  0.7058206775700934 , sd:  0.0312\n",
      "min:  0.6313522196261683\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_loader) for model in  sampled_adv_models]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN(eps=0.18) vs Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.7452540887850467\n",
      "mean:  0.6823890186915889 , sd:  0.0362\n",
      "min:  0.584331191588785\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_loader) for model in  sampled_adv_models_e18]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BNN vs. Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.7538697429906542\n",
      "mean:  0.6652745327102805 , sd:  0.0452\n",
      "min:  0.5505257009345794\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_loader) for model in  sampled_models]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Test (FF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [d for d in os.listdir(\"mnist_adv_eps0.05/\") if \"test_images_FF0.05\" in d]\n",
    "\n",
    "images  = []\n",
    "targets = []\n",
    "for d in dirs:\n",
    "    with open(\"mnist_adv_eps0.05/\"+d, 'rb') as handle:\n",
    "        temp = pickle.load(handle)\n",
    "        images.append(temp[\"images\"])\n",
    "        targets.append(temp[\"labels\"])\n",
    "        \n",
    "images  = torch.vstack(images)\n",
    "targets = torch.hstack(targets)\n",
    "# Test dataset\n",
    "test_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "# Test data loader with batch_size 128\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))\n",
    "\n",
    "# AdvTest dataset\n",
    "adv_test_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=torchvision.transforms.ToTensor())\n",
    "adv_test_dataset.data    = None\n",
    "adv_test_dataset.targets = None\n",
    "\n",
    "adv_test_dataset.data    = images\n",
    "adv_test_dataset.targets = targets\n",
    "\n",
    "# Test data loader with batch_size 1\n",
    "adv_test_loader = torch.utils.data.DataLoader(adv_test_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFNN vs AdvFFNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9741"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(FFNN, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9742"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(AdvFFNN, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9681"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(AdvFFNN_eps18, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adversarial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0979"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(FFNN, adv_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0984"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(AdvFFNN, adv_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0981"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(AdvFFNN_eps18, adv_test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdvBNN vs BNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50 sample models\n",
      "Loaded 50 sample models\n",
      "Loaded 50 sample models\n"
     ]
    }
   ],
   "source": [
    "sampled_models         = load_models(K = 50)\n",
    "sampled_adv_models     = load_models(K = 50, model_dir=\"models/AdvBNN_eps0.05_85.081.pt\")\n",
    "sampled_adv_models_e18 = load_models(K = 50, model_dir=\"models/AdvBNN_eps0.18_87.381.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.8216\n",
      "mean:  0.772208 , sd:  0.0256\n",
      "min:  0.7098\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, test_loader) for model in sampled_adv_models]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN(eps=18) vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = [evaluate_accuracy(model, test_loader) for model in sampled_adv_models_e18]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BNN vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = [evaluate_accuracy(model, test_loader) for model in sampled_models]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN vs Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.1\n",
      "mean:  0.09675999999999998 , sd:  0.0017\n",
      "min:  0.0927\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_loader) for model in  sampled_adv_models]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN(eps=0.18) vs Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.1043\n",
      "mean:  0.10012399999999998 , sd:  0.0025\n",
      "min:  0.0938\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_loader) for model in  sampled_adv_models_e18]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BNN vs. Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.1034\n",
      "mean:  0.09897 , sd:  0.0022\n",
      "min:  0.0929\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_loader) for model in  sampled_models]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(images.reshape(28, 28).detach().numpy())\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow((champ*EPS).reshape(28, 28).detach().numpy(), vmin=-1., vmax=1.)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(new_images.reshape(28, 28).detach().numpy())\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Test (Trained on Champ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [d for d in os.listdir(\"mnist_adv/\") if \"test_images_champ\" in d]\n",
    "\n",
    "images  = []\n",
    "targets = []\n",
    "for d in dirs:\n",
    "    with open(\"mnist_adv/\"+d, 'rb') as handle:\n",
    "        temp = pickle.load(handle)\n",
    "        images.append(temp[\"images\"])\n",
    "        targets.append(temp[\"labels\"])\n",
    "        \n",
    "images  = torch.vstack(images)\n",
    "targets = torch.hstack(targets)\n",
    "# Test dataset\n",
    "test_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "# Test data loader with batch_size 128\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))\n",
    "\n",
    "# AdvTest dataset\n",
    "adv_test_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=torchvision.transforms.ToTensor())\n",
    "adv_test_dataset.data    = None\n",
    "adv_test_dataset.targets = None\n",
    "\n",
    "adv_test_dataset.data    = images\n",
    "adv_test_dataset.targets = targets\n",
    "\n",
    "# Test data loader with batch_size 1\n",
    "adv_test_loader = torch.utils.data.DataLoader(adv_test_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFNN vs AdvFFNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9741"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(FFNN, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9742"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(AdvFFNN, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9681"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(AdvFFNN_eps18, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adversarial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.877197265625"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(FFNN, adv_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8994140625"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(AdvFFNN, adv_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9557291666666666"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(AdvFFNN_eps18, adv_test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdvBNN vs BNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50 sample models\n",
      "Loaded 50 sample models\n",
      "Loaded 50 sample models\n"
     ]
    }
   ],
   "source": [
    "sampled_models         = load_models(K = 50)\n",
    "sampled_adv_models     = load_models(K = 50, model_dir=\"models/AdvBNN_eps0.05_85.081.pt\")\n",
    "sampled_adv_models_e18 = load_models(K = 50, model_dir=\"models/AdvBNN_eps0.18_87.381.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = [evaluate_accuracy(model, test_loader) for model in sampled_adv_models]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN(eps=18) vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = [evaluate_accuracy(model, test_loader) for model in sampled_adv_models_e18]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BNN vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = [evaluate_accuracy(model, test_loader) for model in sampled_models]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN vs Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.1\n",
      "mean:  0.09675999999999998 , sd:  0.0017\n",
      "min:  0.0927\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_loader) for model in  sampled_adv_models]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN(eps=0.18) vs Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.647216796875\n",
      "mean:  0.567529296875 , sd:  0.043\n",
      "min:  0.4576009114583333\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_loader) for model in  sampled_adv_models_e18]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BNN vs. Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.1034\n",
      "mean:  0.09897 , sd:  0.0022\n",
      "min:  0.0929\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_loader) for model in  sampled_models]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(images.reshape(28, 28).detach().numpy())\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow((champ*EPS).reshape(28, 28).detach().numpy(), vmin=-1., vmax=1.)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(new_images.reshape(28, 28).detach().numpy())\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
